{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LHC Machine Learing workshop challenge\n",
    "https://gitlab.cern.ch/IML-WG/IML_challenge_2018/wikis/home\n",
    "\n",
    "Task: Regress the soft-drop mass of jets with high transverse momentum. Jets are complex physical objects, often containing a spray of particles.https://en.wikipedia.org/wiki/Jet_(particle_physics)\n",
    "\n",
    "\n",
    "STEP IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers,optimizers\n",
    "from keras.layers import Reshape,Flatten,Input, Dense, Conv2D, MaxPooling2D, UpSampling2D,ELU,LeakyReLU,Dropout,BatchNormalization,concatenate\n",
    "from keras.models import Model,load_model\n",
    "from keras import backend as K\n",
    "from keras import callbacks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scroll down for metric evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the data\n",
    "import numpy as np\n",
    "\n",
    "my_array=np.load('../data/qcd.npy',encoding='bytes')\n",
    "\n",
    "my_rec_array=my_array.view(np.recarray)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genjet_sd_m\n",
      "genjet_sd_m\n",
      "recojet_pt\n",
      "recojet_eta\n",
      "recojet_phi\n",
      "recojet_m\n",
      "recojet_sd_pt\n",
      "recojet_sd_eta\n",
      "recojet_sd_phi\n",
      "recojet_sd_m\n",
      "n_constituents\n",
      "constituents_pt\n",
      "constituents_eta\n",
      "constituents_phi\n",
      "constituents_charge\n",
      "constituents_dxy\n",
      "constituents_dz\n",
      "constituents_Eem\n",
      "constituents_Ehad\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((729516, 18), (312651, 18))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields=my_array.dtype.names\n",
    "num_jets=my_rec_array.shape[0]\n",
    "for field in fields:\n",
    "    print(field)\n",
    "    x=getattr(my_rec_array,field)\n",
    "    x=np.reshape(x,[1,num_jets])\n",
    "    try:\n",
    "        my_train_val_array=np.concatenate((my_train_val_array,x))\n",
    "    except:\n",
    "        print(field)\n",
    "        my_train_val_array=x\n",
    "my_train_val_array=my_train_val_array.T\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_array, val_array = train_test_split(my_train_val_array, test_size=0.30,random_state=2158)\n",
    "train_array.shape,val_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "reco_features_train=train_array[:,0:10] #recofeatures+target\n",
    "#features1[:3]\n",
    "#const_features_train=train_array[:,9:] #constituents\n",
    "reco_features_val=val_array[:,0:10] #recofeatures+target\n",
    "#features1[:3]\n",
    "#const_features_val=val_array[:,9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 1, 8, 130)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_consts=np.load('train_consts.npz')\n",
    "train_consts.shape\n",
    "val_consts=np.load('val_consts.npz')#!!!!!!change it\n",
    "val_consts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder=load_model('my_encoder2_1058716.48974_93.h5')\n",
    "train_features=encoder.predict(train_consts)\n",
    "val_features=encoder.predict(train_consts)\n",
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 9)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target=reco_features_train[0:3000,0]\n",
    "val_target=reco_features_val[0:3000,0]\n",
    "reco_features_train=reco_features_train[0:3000,1:]\n",
    "reco_features_val=reco_features_train[0:3000,1:]#!!!!!!change it\n",
    "reco_features_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final=np.hstack((reco_features_train,train_features))\n",
    "val_final=np.hstack((reco_features_val,val_features))\n",
    "train_final.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the train regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model=load_model('regressor_trial.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 1)\n"
     ]
    }
   ],
   "source": [
    "train_pred=trained_model.predict(train_final)\n",
    "print(train_pred.shape)\n",
    "#val_pred=trained_model.predict(val_final)\n",
    "train_pred=np.reshape(train_pred,(3000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target.shape==train_pred.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.3294244116103928, 1.2538944687621985, 0.9687673668180001, ...,\n",
       "       0.0, 0.0, 1.0866181416307288], dtype=object)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred/train_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom loss metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_loss(predictions, truth):  \n",
    "     ratio = predictions/truth\n",
    "     a = np.percentile(ratio, 84, interpolation='nearest')  \n",
    "     b = np.percentile(ratio, 16, interpolation='nearest')  \n",
    "     c = np.percentile(ratio, 50, interpolation='nearest')  \n",
    "     loss = (a-b)/(2.*c)  \n",
    "     return loss\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0353009270994566"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_loss(train_pred,train_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same for test cases, and prep file for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields=my_array_test.dtype.names\n",
    "num_jets=my_rec_array_test.shape[0]\n",
    "for field in fields:\n",
    "    print(field)\n",
    "    x=getattr(my_rec_array_test,field)\n",
    "    x=np.reshape(x,[1,num_jets])\n",
    "    try:\n",
    "        my_test_val_array=np.concatenate((my_test_val_array,x))\n",
    "    except:\n",
    "        print(field)\n",
    "        my_test_val_array=x\n",
    "\n",
    "test_array=my_test_val_array.T\n",
    "test_consts=np.load('test_consts_reg.npz')['arr_0']\n",
    "test_features=encoder.predict(test_consts)\n",
    "reco_features_test=reco_features_test[:,:]\n",
    "\n",
    "test_final=np.hstack((reco_features_test,test_features))\n",
    "\n",
    "test_pred=trained_model.predict(test_final)\n",
    "\n",
    "test_pred=np.reshape(test_pred,(test_pred.shape[0]))\n",
    "\n",
    "np.save('regression_target_test3',test_pred) #file for submission\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
