{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LHC Machine Learing workshop challenge\n",
    "https://gitlab.cern.ch/IML-WG/IML_challenge_2018/wikis/home\n",
    "\n",
    "Task: Regress the soft-drop mass of jets with high transverse momentum. Jets are complex physical objects, often containing a spray of particles.https://en.wikipedia.org/wiki/Jet_(particle_physics)\n",
    "\n",
    "STEP III"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reload the data here. Use the constituents put through the trained encoder, the usse the code concatenated along with reconstruted jet quantities as input feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the data\n",
    "import numpy as np\n",
    "\n",
    "my_array=np.load('../data/qcd.npy',encoding='bytes')\n",
    "\n",
    "my_rec_array=my_array.view(np.recarray)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields=my_array.dtype.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genjet_sd_m\n",
      "genjet_sd_m\n",
      "recojet_pt\n",
      "recojet_eta\n",
      "recojet_phi\n",
      "recojet_m\n",
      "recojet_sd_pt\n",
      "recojet_sd_eta\n",
      "recojet_sd_phi\n",
      "recojet_sd_m\n",
      "n_constituents\n",
      "constituents_pt\n",
      "constituents_eta\n",
      "constituents_phi\n",
      "constituents_charge\n",
      "constituents_dxy\n",
      "constituents_dz\n",
      "constituents_Eem\n",
      "constituents_Ehad\n"
     ]
    }
   ],
   "source": [
    "#del my_train_val_array\n",
    "num_jets=my_rec_array.shape[0]\n",
    "for field in fields:\n",
    "    print(field)\n",
    "    x=getattr(my_rec_array,field)\n",
    "    x=np.reshape(x,[1,num_jets])\n",
    "    try:\n",
    "        my_train_val_array=np.concatenate((my_train_val_array,x))\n",
    "    except:\n",
    "        print(field)\n",
    "        my_train_val_array=x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1042167, 18)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_train_val_array=my_train_val_array.T\n",
    "my_train_val_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((729516, 18), (312651, 18))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_array, val_array = train_test_split(my_train_val_array, test_size=0.30,random_state=2158)\n",
    "train_array.shape,val_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reco_features_train=train_array[:,0:10] #recofeatures+target\n",
    "#features1[:3]\n",
    "const_features_train=train_array[:,9:] #constituents\n",
    "reco_features_val=val_array[:,0:10] #recofeatures+target\n",
    "#features1[:3]\n",
    "const_features_val=val_array[:,9:] #constituents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers,optimizers\n",
    "from keras.layers import Reshape,Flatten,Input, Dense,Conv2D, MaxPooling2D, UpSampling2D,ELU,LeakyReLU,Dropout,BatchNormalization,concatenate\n",
    "from keras.models import Model,load_model\n",
    "from keras import backend as K\n",
    "from keras import callbacks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get training constituents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 1, 8, 130)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_consts=np.load('train_consts.npz')\n",
    "train_consts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get validation constituents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 1, 8, 130)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_consts=np.load('train_consts.npz')\n",
    "val_consts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -1.38968982e+03  -1.88133179e+03   4.27937256e+02 ...,  -1.11373009e+02\n",
      "   -1.02983374e+03  -3.97367603e+03]\n",
      " [ -1.84785430e+04  -2.05137285e+04  -1.63939961e+04 ...,  -6.97378174e+03\n",
      "   -3.32072695e+04  -4.56478086e+04]\n",
      " [ -9.36249316e+03  -1.19950879e+04  -5.68674902e+03 ...,  -2.88605396e+03\n",
      "   -2.03736152e+04  -2.75708340e+04]\n",
      " ..., \n",
      " [  1.19594536e+02   1.40916300e+00  -3.01769348e+02 ...,  -5.73151306e+02\n",
      "    3.45790314e+02   5.53951035e+01]\n",
      " [ -1.94455352e+04  -5.01653398e+04   2.11435234e+04 ...,   8.77271680e+03\n",
      "   -3.32262031e+05  -1.91350312e+05]\n",
      " [ -4.48036133e+03  -5.78808655e+02  -7.42071826e+03 ...,  -1.36916467e+03\n",
      "    5.13298767e+02  -2.85274231e+02]]\n"
     ]
    }
   ],
   "source": [
    "encoder=load_model('my_encoder.h5')\n",
    "train_features=encoder.predict(train_consts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000,)\n"
     ]
    }
   ],
   "source": [
    "train_target=reco_features_train[0:3000,0]\n",
    "#train_target=np.reshape(train_target,[tr])\n",
    "print(train_target.shape)\n",
    "reco_features_trial=reco_features_train[0:3000,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stack together code and code from encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final_trial=np.hstack((reco_features_trial,train_features))\n",
    "#train_final_trial=np.reshape(train_final_trial,[train_final_trial.shape[0],1,train_final_trial.shape[1]])\n",
    "train_final_trial.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 59)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 59)                236       \n",
      "_________________________________________________________________\n",
      "densea (Dense)               (None, 400)               24000     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 400)               1600      \n",
      "_________________________________________________________________\n",
      "denseb (Dense)               (None, 300)               120300    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "densec (Dense)               (None, 150)               45150     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 150)               600       \n",
      "_________________________________________________________________\n",
      "densed (Dense)               (None, 50)                7550      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "denseE (Dense)               (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 200,687\n",
      "Trainable params: 198,869\n",
      "Non-trainable params: 1,818\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#regressor model\n",
    "input_vec=Input(shape=(59,))\n",
    "\n",
    "x=BatchNormalization(axis=1)(input_vec)\n",
    "x=Dense(400,name='densea')(x)\n",
    "x=Dropout(0.4)(x)\n",
    "x=LeakyReLU(alpha=0.3)(x)\n",
    "x=BatchNormalization(axis=1)(x)\n",
    "\n",
    "x=Dense(300,name='denseb')(x)\n",
    "x=Dropout(0.4)(x)\n",
    "x=LeakyReLU(alpha=0.3)(x)\n",
    "x=BatchNormalization(axis=1)(x)\n",
    "\n",
    "x=Dense(150,name='densec')(x)\n",
    "x=Dropout(0.3)(x)\n",
    "x=LeakyReLU(alpha=0.3)(x)\n",
    "x=BatchNormalization(axis=1)(x)\n",
    "\n",
    "x=Dense(50,name='densed',activation='elu')(x)\n",
    "#x=BatchNormalization(axis=1)(x)\n",
    "x=Dropout(0.1)(x)\n",
    "#x=LeakyReLU(alpha=0.0001)(x)\n",
    "\n",
    "y_pred=Dense(1,name='denseE',activation='linear')(x)\n",
    "\n",
    "regressor=Model(input_vec,y_pred)\n",
    "regressor.compile(optimizer='adadelta', loss='MSE')\n",
    "regressor.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3000 samples, validate on 3000 samples\n",
      "Epoch 1/1\n",
      "3000/3000 [==============================] - 7s - loss: 80773.7822 - val_loss: 16789.5136\n",
      "Train on 3000 samples, validate on 3000 samples\n",
      "Epoch 1/1\n",
      "3000/3000 [==============================] - 2s - loss: 19394.7496 - val_loss: 20459.6737\n"
     ]
    }
   ],
   "source": [
    "for _ in range(2):#trial, training on gpu-->see train_regressor*.py\n",
    "    sd=regressor.fit(x=train_final_trial, y=train_target, epochs=1,batch_size=32,\n",
    "                validation_data=[train_final_trial,train_target],\n",
    "                verbose=1,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.save('regressor_trial.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model=load_model('regressor_trial.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fourth and final step is using the regressor to evaluate the custom metric a.k.a Resolution of the jet energy scale -->evaluation.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
